{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset directory\n",
    "root_dir = r'D:\\iHT\\texture_recognition_pressure\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with name of videos\n",
    "training_data = pd.DataFrame()\n",
    "videos = []\n",
    "tags = os.listdir(root_dir)\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, dir)\n",
    "\n",
    "    for vid_files in os.listdir(folder_path):\n",
    "        videos.append(vid_files)\n",
    "\n",
    "training_data['videos'] = videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GifDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, fps=30):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.fps = fps\n",
    "        self.gif_files = []\n",
    "        self.labels = []\n",
    "        self._load_gif_files()\n",
    "\n",
    "    def _load_gif_files(self):\n",
    "        for sample_dir in os.listdir(self.root_dir):\n",
    "            sample_path = os.path.join(self.root_dir, sample_dir)\n",
    "            if os.path.isdir(sample_path):\n",
    "                for gif_file in os.listdir(sample_path):\n",
    "                    if gif_file.endswith('.gif'):\n",
    "                        self.gif_files.append(os.path.join(sample_path, gif_file))\n",
    "                        self.labels.append(sample_dir)\n",
    "\n",
    "    def _extract_frames(self, gif_file):\n",
    "        gif = imageio.get_reader(gif_file)\n",
    "        duration = gif.get_meta_data()['duration'] / 1000.0  \n",
    "        total_frames = gif.count_frames()\n",
    "        frame_interval = 1.0 / self.fps  \n",
    "\n",
    "        frames = []\n",
    "\n",
    "        for t in range(0, int(duration * self.fps)):\n",
    "            frame_time = t * frame_interval\n",
    "            frame_index = int(frame_time / (duration / total_frames))\n",
    "            frame = gif.get_data(frame_index)\n",
    "            frame_image = Image.fromarray(frame)\n",
    "            if self.transform:\n",
    "                frame_image = self.transform(frame_image)\n",
    "            frames.append(frame_image)\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gif_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_file = self.gif_files[idx]\n",
    "        frames = self._extract_frames(gif_file)\n",
    "        label = self.labels[idx]\n",
    "        return frames, label\n",
    "\n",
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "root_dir = r'D:\\iHT\\texture_recognition_pressure\\dataset'\n",
    "dataset = GifDataset(root_dir, transform=transform, fps=30)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "feature_vectors = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad(), tqdm(total=len(dataset), desc=f'Extracting Features') as pbar:\n",
    "    for frames, label in dataset:\n",
    "        frames = frames.to(device)\n",
    "\n",
    "        if hasattr(model, 'lstm'):\n",
    "            model.lstm.reset_parameters()\n",
    "\n",
    "        features_vector = model(frames.unsqueeze(0))\n",
    "\n",
    "        feature_vectors.append(features_vector.squeeze().cpu().numpy())\n",
    "        labels.append(label)\n",
    "        pbar.update(1)\n",
    "\n",
    "feature_vectors = np.array(feature_vectors)\n",
    "labels = np.array(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
