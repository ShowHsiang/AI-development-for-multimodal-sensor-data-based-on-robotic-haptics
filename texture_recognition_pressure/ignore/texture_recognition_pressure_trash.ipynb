{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texture Recognition - Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import lightly\n",
    "from lightly.models import utils\n",
    "from lightly.models.modules import heads\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead\n",
    "from lightly.models.modules.heads import SimSiamProjectionHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GifDataset(Dataset):\n",
    "    def __init__(self, gif_dir, transform=None):\n",
    "        self.gif_dir = gif_dir\n",
    "        self.transform = transform\n",
    "        self.gif_files = [os.path.join(gif_dir, f) for f in os.listdir(gif_dir) if f.endswith('.gif')]\n",
    "        self.frames = self._extract_frames()\n",
    "\n",
    "    def _extract_frames(self):\n",
    "        frames = []\n",
    "        total_files = len(self.gif_files)\n",
    "        for i, gif_file in enumerate(self.gif_files):\n",
    "            gif = Image.open(gif_file)\n",
    "            total_frames = gif.n_frames\n",
    "            for frame in range(total_frames):\n",
    "                gif.seek(frame)\n",
    "                frame_image = gif.convert('RGB')\n",
    "                if self.transform:\n",
    "                    frame_image = self.transform(frame_image)\n",
    "                frames.append(frame_image)\n",
    "            # Calculate and print the progress\n",
    "            percent_complete = ((i + 1) / total_files) * 100\n",
    "            print(f'Progress: {percent_complete:.2f}%')\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.frames[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.38%\n",
      "Progress: 0.77%\n",
      "Progress: 1.15%\n",
      "Progress: 1.54%\n",
      "Progress: 1.92%\n",
      "Progress: 2.31%\n",
      "Progress: 2.69%\n",
      "Progress: 3.08%\n",
      "Progress: 3.46%\n",
      "Progress: 3.85%\n",
      "Progress: 4.23%\n",
      "Progress: 4.62%\n",
      "Progress: 5.00%\n",
      "Progress: 5.38%\n",
      "Progress: 5.77%\n",
      "Progress: 6.15%\n",
      "Progress: 6.54%\n",
      "Progress: 6.92%\n",
      "Progress: 7.31%\n",
      "Progress: 7.69%\n",
      "Progress: 8.08%\n",
      "Progress: 8.46%\n",
      "Progress: 8.85%\n",
      "Progress: 9.23%\n",
      "Progress: 9.62%\n",
      "Progress: 10.00%\n",
      "Progress: 10.38%\n",
      "Progress: 10.77%\n",
      "Progress: 11.15%\n",
      "Progress: 11.54%\n",
      "Progress: 11.92%\n",
      "Progress: 12.31%\n",
      "Progress: 12.69%\n",
      "Progress: 13.08%\n",
      "Progress: 13.46%\n",
      "Progress: 13.85%\n",
      "Progress: 14.23%\n",
      "Progress: 14.62%\n",
      "Progress: 15.00%\n",
      "Progress: 15.38%\n",
      "Progress: 15.77%\n",
      "Progress: 16.15%\n",
      "Progress: 16.54%\n",
      "Progress: 16.92%\n",
      "Progress: 17.31%\n",
      "Progress: 17.69%\n",
      "Progress: 18.08%\n",
      "Progress: 18.46%\n",
      "Progress: 18.85%\n",
      "Progress: 19.23%\n",
      "Progress: 19.62%\n",
      "Progress: 20.00%\n",
      "Progress: 20.38%\n",
      "Progress: 20.77%\n",
      "Progress: 21.15%\n",
      "Progress: 21.54%\n",
      "Progress: 21.92%\n",
      "Progress: 22.31%\n",
      "Progress: 22.69%\n",
      "Progress: 23.08%\n",
      "Progress: 23.46%\n",
      "Progress: 23.85%\n",
      "Progress: 24.23%\n",
      "Progress: 24.62%\n",
      "Progress: 25.00%\n",
      "Progress: 25.38%\n",
      "Progress: 25.77%\n",
      "Progress: 26.15%\n",
      "Progress: 26.54%\n",
      "Progress: 26.92%\n",
      "Progress: 27.31%\n",
      "Progress: 27.69%\n",
      "Progress: 28.08%\n",
      "Progress: 28.46%\n",
      "Progress: 28.85%\n",
      "Progress: 29.23%\n",
      "Progress: 29.62%\n",
      "Progress: 30.00%\n",
      "Progress: 30.38%\n",
      "Progress: 30.77%\n",
      "Progress: 31.15%\n",
      "Progress: 31.54%\n",
      "Progress: 31.92%\n",
      "Progress: 32.31%\n",
      "Progress: 32.69%\n",
      "Progress: 33.08%\n",
      "Progress: 33.46%\n",
      "Progress: 33.85%\n",
      "Progress: 34.23%\n",
      "Progress: 34.62%\n",
      "Progress: 35.00%\n",
      "Progress: 35.38%\n",
      "Progress: 35.77%\n",
      "Progress: 36.15%\n",
      "Progress: 36.54%\n",
      "Progress: 36.92%\n",
      "Progress: 37.31%\n",
      "Progress: 37.69%\n",
      "Progress: 38.08%\n",
      "Progress: 38.46%\n",
      "Progress: 38.85%\n",
      "Progress: 39.23%\n",
      "Progress: 39.62%\n",
      "Progress: 40.00%\n",
      "Progress: 40.38%\n",
      "Progress: 40.77%\n",
      "Progress: 41.15%\n",
      "Progress: 41.54%\n",
      "Progress: 41.92%\n",
      "Progress: 42.31%\n",
      "Progress: 42.69%\n",
      "Progress: 43.08%\n",
      "Progress: 43.46%\n",
      "Progress: 43.85%\n",
      "Progress: 44.23%\n",
      "Progress: 44.62%\n",
      "Progress: 45.00%\n",
      "Progress: 45.38%\n",
      "Progress: 45.77%\n",
      "Progress: 46.15%\n",
      "Progress: 46.54%\n",
      "Progress: 46.92%\n",
      "Progress: 47.31%\n",
      "Progress: 47.69%\n",
      "Progress: 48.08%\n",
      "Progress: 48.46%\n",
      "Progress: 48.85%\n",
      "Progress: 49.23%\n",
      "Progress: 49.62%\n",
      "Progress: 50.00%\n",
      "Progress: 50.38%\n",
      "Progress: 50.77%\n",
      "Progress: 51.15%\n",
      "Progress: 51.54%\n",
      "Progress: 51.92%\n",
      "Progress: 52.31%\n",
      "Progress: 52.69%\n",
      "Progress: 53.08%\n",
      "Progress: 53.46%\n",
      "Progress: 53.85%\n",
      "Progress: 54.23%\n",
      "Progress: 54.62%\n",
      "Progress: 55.00%\n",
      "Progress: 55.38%\n",
      "Progress: 55.77%\n",
      "Progress: 56.15%\n",
      "Progress: 56.54%\n",
      "Progress: 56.92%\n",
      "Progress: 57.31%\n",
      "Progress: 57.69%\n",
      "Progress: 58.08%\n",
      "Progress: 58.46%\n",
      "Progress: 58.85%\n",
      "Progress: 59.23%\n",
      "Progress: 59.62%\n",
      "Progress: 60.00%\n",
      "Progress: 60.38%\n",
      "Progress: 60.77%\n",
      "Progress: 61.15%\n",
      "Progress: 61.54%\n",
      "Progress: 61.92%\n",
      "Progress: 62.31%\n",
      "Progress: 62.69%\n",
      "Progress: 63.08%\n",
      "Progress: 63.46%\n",
      "Progress: 63.85%\n",
      "Progress: 64.23%\n",
      "Progress: 64.62%\n",
      "Progress: 65.00%\n",
      "Progress: 65.38%\n",
      "Progress: 65.77%\n",
      "Progress: 66.15%\n",
      "Progress: 66.54%\n",
      "Progress: 66.92%\n",
      "Progress: 67.31%\n",
      "Progress: 67.69%\n",
      "Progress: 68.08%\n",
      "Progress: 68.46%\n",
      "Progress: 68.85%\n",
      "Progress: 69.23%\n",
      "Progress: 69.62%\n",
      "Progress: 70.00%\n",
      "Progress: 70.38%\n",
      "Progress: 70.77%\n",
      "Progress: 71.15%\n",
      "Progress: 71.54%\n",
      "Progress: 71.92%\n",
      "Progress: 72.31%\n",
      "Progress: 72.69%\n",
      "Progress: 73.08%\n",
      "Progress: 73.46%\n",
      "Progress: 73.85%\n",
      "Progress: 74.23%\n",
      "Progress: 74.62%\n",
      "Progress: 75.00%\n",
      "Progress: 75.38%\n",
      "Progress: 75.77%\n",
      "Progress: 76.15%\n",
      "Progress: 76.54%\n",
      "Progress: 76.92%\n",
      "Progress: 77.31%\n",
      "Progress: 77.69%\n",
      "Progress: 78.08%\n",
      "Progress: 78.46%\n",
      "Progress: 78.85%\n",
      "Progress: 79.23%\n",
      "Progress: 79.62%\n",
      "Progress: 80.00%\n",
      "Progress: 80.38%\n",
      "Progress: 80.77%\n",
      "Progress: 81.15%\n",
      "Progress: 81.54%\n",
      "Progress: 81.92%\n",
      "Progress: 82.31%\n",
      "Progress: 82.69%\n",
      "Progress: 83.08%\n",
      "Progress: 83.46%\n",
      "Progress: 83.85%\n",
      "Progress: 84.23%\n",
      "Progress: 84.62%\n",
      "Progress: 85.00%\n",
      "Progress: 85.38%\n",
      "Progress: 85.77%\n",
      "Progress: 86.15%\n",
      "Progress: 86.54%\n",
      "Progress: 86.92%\n",
      "Progress: 87.31%\n",
      "Progress: 87.69%\n",
      "Progress: 88.08%\n",
      "Progress: 88.46%\n",
      "Progress: 88.85%\n",
      "Progress: 89.23%\n",
      "Progress: 89.62%\n",
      "Progress: 90.00%\n",
      "Progress: 90.38%\n",
      "Progress: 90.77%\n",
      "Progress: 91.15%\n",
      "Progress: 91.54%\n",
      "Progress: 91.92%\n",
      "Progress: 92.31%\n",
      "Progress: 92.69%\n",
      "Progress: 93.08%\n",
      "Progress: 93.46%\n",
      "Progress: 93.85%\n",
      "Progress: 94.23%\n",
      "Progress: 94.62%\n",
      "Progress: 95.00%\n",
      "Progress: 95.38%\n",
      "Progress: 95.77%\n",
      "Progress: 96.15%\n",
      "Progress: 96.54%\n",
      "Progress: 96.92%\n",
      "Progress: 97.31%\n",
      "Progress: 97.69%\n",
      "Progress: 98.08%\n",
      "Progress: 98.46%\n",
      "Progress: 98.85%\n",
      "Progress: 99.23%\n",
      "Progress: 99.62%\n",
      "Progress: 100.00%\n"
     ]
    }
   ],
   "source": [
    "gif_dataset = GifDataset(r'D:\\iHT\\texture_recognition_pressure\\sample testing', transform=transform)\n",
    "gif_dataloader = DataLoader(gif_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = 512\n",
    "# dimension of the output of the prediction and projection heads\n",
    "out_dim = proj_hidden_dim = 512\n",
    "# the prediction head uses a bottleneck architecture\n",
    "pred_hidden_dim = 128\n",
    "\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(\n",
    "        self, backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SimSiamProjectionHead(\n",
    "            num_ftrs, proj_hidden_dim, out_dim\n",
    "        )\n",
    "        self.prediction_head = SimSiamPredictionHead(\n",
    "            out_dim, pred_hidden_dim, out_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get representations\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        # get projections\n",
    "        z = self.projection_head(f)\n",
    "        # get predictions\n",
    "        p = self.prediction_head(z)\n",
    "        # stop gradient\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "\n",
    "# we use a pretrained resnet for this tutorial to speed\n",
    "# up training time but you can also train one from scratch\n",
    "resnet = torchvision.models.resnet18()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimSiam uses a symmetric negative cosine similarity loss\n",
    "criterion = lightly.loss.NegativeCosineSimilarity()\n",
    "\n",
    "# scale the learning rate\n",
    "lr = 0.1\n",
    "\n",
    "# use SGD with momentum and weight decay\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
